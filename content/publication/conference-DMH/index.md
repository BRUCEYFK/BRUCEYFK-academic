---
title: 'Efficient Policy Learning for General Robotic Tasks with Adaptive Dual-memory Hindsight Experience Replay Based on Deep Reinforcement Learning'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - Menghua Dong
  - Admin
  - Xiangjian Li
  - Huashan Liu

# Author notes (optional)
author_notes:
  # - ''
  # - ''

date: '2023-01-05T00:00:00Z'
doi: '10.1109/ICRCA57894.2023.10087824'

# Schedule page publish date (NOT publication's date).
# publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['1']

# Publication name and optional abbreviated publication name.
publication: In *2023 7th International Conference on Robotics, Control and Automation (ICRCA)*
# publication_short: In *ICRCA*

abstract: Deep reinforcement learning (DRL) features powerful ability of perception and decision-making, which is reward-driven and learns strategies through the interaction between the agent and the environment. However, the discrete reward mechanism makes it difficult for DRL to obtain positive feedback in the early stage of interaction, resulting in low learning efficiency. The hindsight experience replay (HER) mechanism can improve the deficiency of the discrete reward, but it also causes a lot of data redundancy. This paper proposes an adaptive dual-memory hindsight experience replay structure. The success rate of the algorithm can be improved while the training efficiency can be ensured by using the dual-memory bank structure to split the empirical data and adjusting the proportion of HER mechanism. The proposed method is applied to the DRL algorithm and verified on a 7-DoF robot, and experimental results show that the algorithm has good performance.

# Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags:
  - Academic
  - Deep Reinforcement Learning
  - Robotics
  - Motion Planning

# Display this page in the Featured widget?
featured: False

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: 'https://ieeexplore.ieee.org/document/10087824'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

